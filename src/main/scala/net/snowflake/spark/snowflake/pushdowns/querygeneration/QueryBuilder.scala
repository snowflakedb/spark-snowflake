package net.snowflake.spark.snowflake.pushdowns.querygeneration

import java.util.NoSuchElementException

import net.snowflake.spark.snowflake.{
  SnowflakePushdownException,
  SnowflakeRelation
}
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.sql.catalyst.expressions.{Attribute, Literal}
import org.apache.spark.sql.catalyst.plans._
import org.apache.spark.sql.catalyst.plans.logical._
import org.apache.spark.sql.execution.datasources.LogicalRelation
import org.apache.spark.sql.types.{StructField, StructType}

import scala.reflect.ClassTag

/** This class takes a Spark LogicalPlan and attempts to generate
  * a query for Snowflake using tryBuild(). Here we use lazy instantiation
  * to avoid building the query from the get-go without tryBuild().
  * TODO: Is laziness actually helpful?
  */
private[querygeneration] class QueryBuilder(plan: LogicalPlan) {

  /** This iterator automatically increments every time it is used, and is for aliasing subqueries. */
  private final val alias = Iterator.from(0).map(n => s"subquery_$n")

  /** RDD of [InternalRow] to be used by SnowflakePlan. */
  lazy val rdd = toRDD[InternalRow]

  /** When referenced, attempts to translate the Spark plan to a SQL query that can be executed
    * by Snowflake. It will be null if this fails.
    */
  lazy val tryBuild: Option[QueryBuilder] =
    if (treeRoot == null) None else Some(this)

  /** Represents the top-level (outermost) query represented by the generated tree. */
  lazy val query: String = {
    checkTree()
    val query = treeRoot.getQuery()
    //log.info(s"""Generated query: '${prettyPrint(query)}'""")
    query
  }

  /** Fetch the output attributes for Spark. */
  lazy val getOutput = {
    checkTree()
    treeRoot.output
  }

  /** Finds the SourceQuery in this given tree. */
  private lazy val source = {
    checkTree()
    treeRoot.find {
      case q: SourceQuery => q
    }.getOrElse(
      throw new SnowflakePushdownException(
        "Something went wrong: a query tree was generated with no " +
          "Snowflake SourceQuery found.")
    )
  }

  /** Top level query generated by the QueryGenerator. Lazily computed. */
  private lazy val treeRoot: SnowflakeQuery = {
    try {
      log.debug("Begin query generation.")
      generateQueries(plan).get
    } catch {
      case _: MatchError | _: NoSuchElementException => {
        log.debug("Could not generate a query.")
      }
      null
    }
  }

  /** Invokes buildScan in SnowflakeRelation to build the RDD from a generated query. */
  private def toRDD[T: ClassTag]: RDD[T] = {

    val schema = StructType(getOutput.map(attr =>
      StructField(attr.name, attr.dataType, attr.nullable)))

    source.relation.buildScanFromSQL[T](query, Some(schema))
  }

  private def checkTree(): Unit = {
    if (treeRoot == null) {
      throw new SnowflakePushdownException(
        "QueryBuilder's tree accessed without generation.")
    }
  }

  /** Attempts to generate the query from the LogicalPlan. The queries are constructed from
    * the bottom up, but the validation of supported nodes for translation happens on the way down.
    *
    * @param plan The LogicalPlan to be processed.
    * @return An object of type Option[SnowflakeQuery], which is None if the plan contains an
    *         unsupported node type.
    */
  private def generateQueries(plan: LogicalPlan): Option[SnowflakeQuery] = {
    plan match {
      case l @ LogicalRelation(sfRelation: SnowflakeRelation, _, _) =>
        Some(SourceQuery(sfRelation, l.output, alias.next))

      case UnaryOp(child) =>
        generateQueries(child) map { subQuery =>
          plan match {
            case Filter(condition, _) =>
              FilterQuery(Seq(condition), subQuery, alias.next)
            case Project(fields, _) =>
              ProjectQuery(fields, subQuery, alias.next)
            case Aggregate(groups, fields, _) =>
              AggregateQuery(fields, groups, subQuery, alias.next)
            case Limit(limitExpr, _) =>
              SortLimitQuery(Some(limitExpr), Seq.empty, subQuery, alias.next)
            case Limit(limitExpr, Sort(orderExpr, true, _)) =>
              SortLimitQuery(Some(limitExpr), orderExpr, subQuery, alias.next)

            case Sort(orderExpr, true, Limit(limitExpr, _)) =>
              SortLimitQuery(Some(limitExpr), orderExpr, subQuery, alias.next)
            case Sort(orderExpr, true, _) =>
              SortLimitQuery(None, orderExpr, subQuery, alias.next)

            case _ => subQuery
          }
        }

      case BinaryOp(left, right) =>
        generateQueries(left).flatMap { l =>
          generateQueries(right) map { r =>
            plan match {
              case Join(_, _, joinType, condition) =>
                joinType match {
                  case Inner | LeftOuter | RightOuter | FullOuter =>
                    JoinQuery(l, r, condition, joinType, alias.next)
                  case LeftSemi =>
                    LeftSemiJoinQuery(l, r, condition, false, alias)
                  case LeftAnti =>
                    LeftSemiJoinQuery(l, r, condition, true, alias)
                  case _ => throw new MatchError
                }
            }
          }
        }

      case _ => None
    }
  }
}

/** QueryBuilder object that serves as an external interface for building queries.
  * Right now, this is merely a wrapper around the QueryBuilder class.
  */
private[snowflake] object QueryBuilder {

  def getRDDFromPlan(
      plan: LogicalPlan): Option[(Seq[Attribute], RDD[InternalRow])] = {
    val qb = new QueryBuilder(plan)

    qb.tryBuild.map { executedBuilder =>
      (executedBuilder.getOutput, executedBuilder.rdd)
    }
  }
}
