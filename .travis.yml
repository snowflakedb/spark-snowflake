language: scala
sudo: false
cache:
  directories:
    - $HOME/.ivy2

# There's no nicer way to specify this matrix; see
# https://github.com/travis-ci/travis-ci/issues/1519.
# Spark 1.5.0 only supports Java 7+.
matrix:
  include:
    # We only test Spark 1.4.1 with Hadooop 2.2.0 because
    # https://github.com/apache/spark/pull/6599 is not present in 1.4.1,
    # so the published Spark Maven artifacts will not work with Hadoop 1.x.
    #- jdk: openjdk6
    #  scala: 2.10.5
    #  env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.4.1"
    #- jdk: openjdk7
    #  scala: 2.10.5
    #  env: HADOOP_VERSION="1.0.4" SPARK_VERSION="1.5.0"
    
    #- jdk: openjdk7
    #  scala: 2.10.5
    #  env: HADOOP_VERSION="1.2.1" SPARK_VERSION="1.5.0"
    #- jdk: openjdk7
    #  scala: 2.10.5
    #  env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.5.0"
    ## Scala 2.11 tests:
    #- jdk: openjdk7
    #  scala: 2.11.7
    #  env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.5.0"
    #- jdk: openjdk7
    #  scala: 2.11.7
    #  env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.6.2" 
    - jdk: openjdk7
      scala: 2.11.7
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.6.2" INTEGRATION_TESTS="true"

env:
  global:
    # IT_SNOWFLAKE_CONF_BASE64
    # - secure: "something"

script:
  - ./dev/run-tests-travis.sh

after_success:
  - bash <(curl -s https://codecov.io/bash)

before_install:
- openssl aes-256-cbc -K $encrypted_d012194b3dc9_key -iv $encrypted_d012194b3dc9_iv -in snowflake.travis.conf.enc -out snowflake.travis.conf -d
